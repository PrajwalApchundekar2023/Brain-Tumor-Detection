"""Performace-Test-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HmtOGiEycXT5ut1yrOXRIGEUQ9mD1pVy

# **Performace test - 1**
This project is a healthcare chatbot designed to predict diseases based on user-provided symptoms. Utilizing machine learning algorithms such as Decision Tree and Support Vector Classifier (SVC), the chatbot interacts with users through text and voice to assist in diagnosing possible medical conditions with a high degree of accuracy. The chatbot also provides health-related precautions and descriptions for suggested conditions.

### **Machine Learning**
END TO END PROCESS:
●	Pandas for data manipulation.
●	scikit-learn for machine learning (Decision Tree and SVC).
●	pyttsx3 for text-to-speech functionality.
●	NumPy for numerical computations.
●	CSV for reading and managing symptom data.
1.	Training Dataset: Contains multiple symptoms and the corresponding disease diagnosis.
2.	Testing Dataset: Used to evaluate the performance of the model.
3.	Symptom_Description.csv: Contains detailed descriptions for each disease.
4.	Symptom_severity.csv: Maps symptoms to their severity levels.
5.	Symptom_precaution.csv: Lists the precautions for each disease.


> Add blockquote
"""

import pandas as pd
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# CNN or Uploading the CSV
data = pd.read_csv('/content/Brain Tumor.csv')
data.head()

from torchvision import transforms
from PIL import Image

import torch

import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.models as models
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Dataset

import os

device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# By using the Parameters
batch_size=32;
num_epochs=10;
learning_rate=0.001;

class BrainTumorDataset(Dataset):
  def __init__(self, dataframe, transform=None):
    self.dataframe = dataframe
    self.transform = transform

  def __len__(self):
    return len(self.dataframe)

  def __getitem__(self, idx):
    img_path = self.dataframe.iloc[idx, 0]
    label = self.dataframe.iloc[idx, 1]
    image = Image.open(img_path)

    if self.transform:
      image = self.transform(image)

    return image, torch.tensor(label)

transfrom = transforms.Compose([

    transforms.Resize((128, 128)),
    transforms.ToTensor(), # for Convert Image to tenser
    transforms.Normalize(mean=[0.5], std=[0.5])
])

# For the spliting
train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)

# By creating the custom data set
train_dataset = BrainTumorDataset(train_data, transform=transfrom)
val_dataset = BrainTumorDataset(val_data, transform=transfrom)

# By seening the Above value data load
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

# By using the Model CNN
# defining the Class
class BrainTumorModel(nn.Module):
  def __init__(self):
    super(BrainTumorModel, self).__init__()
    self.conv1= nn.Conv2d(1,32,3,1)
    self.conv2= nn.Conv2d(32,64,3,1)
    self.fc1= nn.Linear(64*30*30, 128)
    self.fc2= nn.Linear(128,2)

  def forward(self, x):
    x= F.relu(self.conv1(x))
    x= F.max_pool2d(x,2)
    x= F.relu(self.conv2(x))
    x= F.max_pool2d(x,2)
    x= torch.flatten(x,1)
    x= F.relu(self.fc1(x))
    x= self.fc2(x)
    return x

# By using the Initilizing the Model of Functions of Optimizer and Losser
model = BrainTumorModel().to(device)
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
criterion = nn.CrossEntropyLoss()

def train_model(model, train_loader, val_loader, num_epochs, criterion, optimizer):
  model.train()
  for epoch in range(num_epochs):
    train_loss = 0.0;

    for images, labels in train_loader:
      images, labels = images.to(device), labels.to(device)

      # By forwarding the Element
      outputs = model(images)
      loss = criterion(outputs, labels)

      # By Backpropagation
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()

      train_loss += loss.item()

    # Now its Validation
    val_loss = 0.0
    model.eval()

    with torch.no_grad():
      for images, labels in val_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels)
        val_loss += loss.item();

        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}')
    # Training the Model
    train_model(model, train_loader, val_loader, num_epochs, criterion, optimizer)

# For the Prediction Function
def predict(image_path,model):
  image = Image.open(image_path).convert('L')
  image = transfrom(image).unsqueeze(0).to(device)
  model.eval()
  with torch.no_grad():
    outputs = model(image)
    predicted = torch.argmax(outputs, dim=1).item()
  return predicted

# Usage of prediction
test_image_path=''
result=predict(test_image_path, model);
print(f'Prediction : {result}')
print('Tumor Detected' if result == 1 else 'No Tumor Detected')

